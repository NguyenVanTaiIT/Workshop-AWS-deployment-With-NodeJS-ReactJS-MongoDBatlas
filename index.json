[
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/2-preparation/2.3-create-beanstalk/2.3.1-create-eb-env/",
	"title": "Create and Configure Elastic Beanstalk Environment",
	"tags": [],
	"description": "",
	"content": "In this step, you will create and configure an Elastic Beanstalk environment to host your Node.js backend.\nYou will:\nUpload the zipped backend source Set up environment variables Attach the IAM instance role Enable AWS X-Ray daemon for tracing Deploy and validate the backend application üì¶ Step 1: Prepare Backend Source Code Download the backend source code (already configured for Beanstalk + X-Ray):\n‚¨áÔ∏è Download Workshop backend Source Code(backend.zip)\nAfter downloading, extract and re-zip the contents of the backend/ folder (not the folder itself):\ncd backend zip -r ../ecommerce-backend.zip . üîê Step 2: Prepare Environment Variables Use this .env template for local development or apply as environment variables in Beanstalk:\nPORT=8080 ALLOWED_ORIGINS=http://your-backend-url.elasticbeanstalk.com,http://localhost:5173 JWT_SECRET=your-jwt-secret-key REFRESH_TOKEN_SECRET=your-refresh-token-secret-key SECRET_NAME=your-secret-name AWS_REGION=ap-southeast-1 NODE_ENV=development ENABLE_XRAY=true XRAY_DAEMON_ADDRESS=127.0.0.1:2000 MONGODB_URI=mongodb+srv://your-username:your-password@cluster0.mongodb.net/?retryWrites=true\u0026amp;w=majority\u0026amp;appName=Cluster0 AWS_ACCESS_KEY=your-aws-access-key AWS_SECRET_KEY=your-aws-secret-key ‚ö†Ô∏è Store sensitive keys (e.g., AWS \u0026amp; MongoDB credentials) securely in AWS Secrets Manager.\n‚òÅÔ∏è Step 3: Create Elastic Beanstalk Environment Go to the Elastic Beanstalk Console\nElastic Beanstalk Console Click Create Application Fill in: Application name: ecommerce-app Under Platform: Platform: Node.js Platform Branch: Node.js 20 running on 64bit Amazon Linux 2023 Under Application code: Choose Upload your code Upload: ecommerce-backend.zip Select Platform and Upload Application Environment Type and Upload ZIP ‚öôÔ∏è Step 4: Configure Service Access Attach IAM Role to EC2 instance This IAM role allows the EC2 instance to access Secrets Manager, S3, and X-Ray\n‚öôÔ∏è Step 5: Enable Monitoring and X-Ray Under Monitoring enable AWS X-Ray tracing\nEnable X-Ray daemon in environment settings Click Apply.\nAfter that, review all settings, then click Create environment\n‚öôÔ∏è Step 6: Set Environment Variables Once the environment is up and running:\nGo to the Configuration tab Click Edit Edit software settings to add environment variables Copy the following variables:\nPORT=8080 NODE_ENV=production AWS_XRAY_DAEMON_ADDRESS=127.0.0.1:2000 JWT_SECRET=your-jwt-secret-key REFRESH_TOKEN_SECRET=your-refresh-token-secret-key ALLOWED_ORIGINS=http://localhost:5173,https://your-frontend Click Add environment property. Set environment variables Click Apply to save changes.\nüí° You may also add variables like SECRET_NAME, AWS_ACCESS_KEY, and AWS_SECRET_KEY if your app doesn\u0026rsquo;t fetch from Secrets Manager yet.\n‚úÖ Step 7: Validate Deployment Once deployed, visit your environment URL (e.g.):\nhttp://ecommerce-env.eba-xxxx.ap-southeast-1.elasticbeanstalk.com Test the following endpoints:\nGET /api/status GET /health GET /api/products üß™ Verify: ‚úÖ API responds with 200 OK ‚úÖ /health returns: database: connected xray: enabled ‚úÖ Traces appear in AWS X-Ray \u0026gt; Service Map üß© Troubleshooting\n‚ùå App crash or white screen? ‚Üí Check Logs ‚Üí Last 100 lines in EB console ‚ùå MongoDB not connected? ‚Üí Check if secret mongodb/connection exists and IAM role has permission ‚ùå No traces? ‚Üí Make sure .ebextensions/01_xray.config exists and IAM role has AWSXRayFullAccess üéâ Congratulations! You have successfully deployed a production-ready backend with AWS Elastic Beanstalk, connected to MongoDB Atlas, integrated with AWS X-Ray, and ready for scaling.\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/2-preparation/2.2-iam-and-secrets/2.2.1-create-iam-user/",
	"title": "Create IAM User for Development",
	"tags": [],
	"description": "",
	"content": "In this step, you\u0026rsquo;ll create an IAM user with programmatic access, which will be used for local development and testing using the AWS CLI or SDKs.\nüß© IAM Policies to Attach You will assign the following policies to the user:\nAmazonS3FullAccess SecretsManagerReadWrite AWSXRayFullAccess These permissions will allow you to:\nUpload product images to S3 Access secrets stored in AWS Secrets Manager Send trace data to AWS X-Ray from your backend app üìù Steps 1. Go to the IAM Console IAM Console Home 2. In the left sidebar, click Users ‚Üí then click Add users Add new IAM User 3. Configure User Details User name: ecommerce-user Provide user access to the AWS Management Console - optional (check this) Click I want to create an IAM user In the Console access section, you can choose Autogenerated password or select Custom password if you prefer to set your own. Configure user details Click Next 4. Set Permissions Choose Attach policies directly Search and select: AmazonS3FullAccess SecretsManagerReadWrite AWSXRayFullAccess Click Next Set permissions for IAM user 5. Review and Create Review the user details and attached permissions Click Create user Review and create IAM user 7. Verify user Once the user is created:\nClick Download .csv file\nThis file contains your Username and Password IAM User successfully created You will not be able to view the secret access key again, so save the file securely.\nClick View user to return to the user details page You should now see the new user listed in the IAM Console 8. Create Access Key On the user details page, go to the Security credentials tab\nScroll down to the Access keys section\nClick Create access key\nIn the use case prompt, select:\nCommand Line Interface (CLI) Create access key for IAM user Create access key for IAM user Click Next ‚Üí then Create access key\nCopy the Access key ID and Secret access key, or download them as .csv\nThis is the only time you will see the secret access key.\nMake sure to download or copy it and store it securely.\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/2-preparation/2.1-create-mongodb-atlas-db/",
	"title": "Create MongoDB Atlas Database for Development",
	"tags": [],
	"description": "",
	"content": "Create a MongoDB Atlas Database Step-by-step guide to create a new database on MongoDB Atlas for your MERN stack application.\nüß≠ Steps: Log in to MongoDB Atlas. Log in to MongoDB Atlas Dashboard Create a new Project (if you haven\u0026rsquo;t already). Log in to MongoDB Atlas Dashboard Name your project: (e.g. Xray) Log in to MongoDB Atlas Dashboard Click Next and Create project Log in to MongoDB Atlas Dashboard Create a new Cluster Click Build a Database in MongoDB Atlas Choose your preferred Cloud Provider, Cluster Tier/Template, and Region Choose Cloud Provider, Template, and Region After selecting the options, click Create Deployment to begin provisioning your cluster Create MongoDB Cluster Deployment Set up Network Access and Create a Database User After your cluster is deployed, MongoDB Atlas will guide you through the connection setup process.\nStep 1: Add IP address and Create user Your current IP address will be automatically added to the whitelist.\nA default database user is also suggested.\nStep 2: Set Username and Password You can use the autogenerated credentials or create your own.\nClick Copy (1) to save the password, then click Create Database User (2). Add IP address and prepare to create database user Step 3: Choose connection method After the user is created, click Choose a connection method. Create MongoDB database user and copy credentials Step 4: Select \u0026lsquo;Drivers\u0026rsquo; and choose Node.js In the next screen, select Drivers, then pick Node.js as your driver and version. Choose a connection method for MongoDB Atlas üí° The connection string shown here will contain your username and password.\nClick the Copy button and save the string ‚Äî you will use it in your backend application.\nThis is the only time the password will be visible, so store it securely or immediately add it to AWS Secrets Manager.\nGet connection string with Node.js driver Once completed, you will receive a MongoDB connection URI, which will be used by your Node.js backend (typically stored in Secrets Manager).\nüîê Manage Database Access (Username \u0026amp; Password) To update or reset your MongoDB username/password after initial setup:\nIn the left menu of MongoDB Atlas Console, click Database Access under Security.\nYou‚Äôll see a list of existing users.\nClick the Edit button next to the user you want to modify.\nEdit MongoDB database user In the modal:\nTo change the password, enter the new password To change roles, select different access levels (e.g., readWrite, atlasAdmin) To delete the user, click Delete Click Update User to save your changes.\nDon‚Äôt forget to update the connection string or secret in AWS Secrets Manager if the password has changed.\nüåê Manage Network Access (IP Whitelist) To change which IPs can access your MongoDB cluster:\nIn the left menu, click Network Access under Security.\nYou\u0026rsquo;ll see the IP Access List.\nMongoDB Atlas IP Whitelist Management To add a new IP:\nClick Add IP Address You can choose: Current IP (auto-detected) A specific IP (e.g., 203.0.113.4) Or Allow Access from Anywhere (0.0.0.0/0) to allow all (not recommended for production) To delete or modify an existing IP, click the options (three dots ...) next to the entry.\nIP changes take effect within seconds, no need to restart your cluster.\nNow you know how to manage access and security for your MongoDB Atlas environment.\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/2-preparation/2.5-s3-setup/2.5.1-create-bucket/",
	"title": "Create S3 Bucket for Product Images",
	"tags": [],
	"description": "",
	"content": "In this step, you\u0026rsquo;ll create a new Amazon S3 bucket to store and serve product images for your e-commerce application.\nThe backend is already preconfigured to upload to a bucket named: ecommerce-products-2025\nMake sure you create a bucket with this exact name (or update the backend code accordingly).\nü™£ Step-by-step: Create a New S3 Bucket Go to the Amazon S3 Console\nClick Create bucket Amazon Simple Storage Service (Amazon S3) Fill in the following:\nBucket name: ecommerce-products-2025\nRegion:\nChoose the same AWS Region where your Beanstalk environment is running (e.g., ap-southeast-1)\nAmazon Simple Storage Service (Amazon S3) üîê Step 2: Disable Block Public Access Scroll down to the Block Public Access settings\nUncheck: Block all public access\nAcknowledge the warning that pops up, then click Create bucket\nAmazon Simple Storage Service (Amazon S3) Amazon Simple Storage Service (Amazon S3) üìõ Step 3: Add Bucket Policy (Optional for Public Read) If you\u0026rsquo;d like your product images to be publicly viewable (without signed URLs), add the following Bucket Policy:\nGo to your newly created bucket Choose the Permissions tab Click Edit under Bucket Policy, and paste the following: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowUserS3Access\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::\u0026lt;your-account-id\u0026gt;:user/\u0026lt;your-username\u0026gt;\u0026#34; }, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::ecommerce-products-2025/*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;PublicReadAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::ecommerce-products-2025/*\u0026#34; } ] } üîç Explanation of Permissions\nSID Purpose AllowUserS3Access Allows a specific IAM user to upload, read, and delete objects inside the bucket. PublicReadAccess Allows the general public (anyone) to read (GET) files in the bucket, such as images. üëâ Continue: 2.5.2 ‚Äì Configure CORS for S3 Bucket\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/4-deployment/4.1-deploy-backend/",
	"title": "Deploy Backend to AWS Elastic Beanstalk",
	"tags": [],
	"description": "",
	"content": "In this step, your Node.js backend should now be deployed to AWS Elastic Beanstalk with:\nAWS X-Ray tracing enabled MongoDB Atlas connected securely via Secrets Manager Environment variables configured properly Health check and graceful shutdown implemented ‚úÖ If you\u0026rsquo;ve already completed the setup in Section 2.3.1 ‚Äì Create and Configure Elastic Beanstalk Environment, you\u0026rsquo;re good to go!\nüß™ Validate Deployment Access your Elastic Beanstalk environment (e.g.):\nhttp://ecommerce-env.eba-xxxx.ap-southeast-1.elasticbeanstalk.com Then test these endpoints:\nGET /api/status GET /health GET /api/products You should expect:\n‚úÖ HTTP 200 responses ‚úÖ /health returns xray: enabled and database: connected ‚úÖ Traces appear in AWS X-Ray ‚Üí Service Map ‚ùó Didn\u0026rsquo;t deploy yet? Go back to: üëâ 2.3.1 ‚Äì Create and Configure Elastic Beanstalk Environment\nThere you\u0026rsquo;ll learn how to:\nUpload your zipped backend code Configure environment variables Attach IAM roles Enable X-Ray daemon üéâ Once done, you have a full-featured Node.js backend running on Elastic Beanstalk with tracing, observability, and production readiness.\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "This workshop introduces end-to-end tracing and monitoring of a Node.js + React e-commerce application using AWS services such as X-Ray, CloudWatch, Secrets Manager, and Elastic Beanstalk. You will learn how to trace user requests across services, visualize latency bottlenecks, debug backend logic, and securely manage application secrets‚Äîall within AWS.\nWe will use MongoDB Atlas for database storage, Amazon S3 for image uploads, and Elastic Beanstalk for deployment. The frontend (React Vite) and backend (Node.js with Express) are integrated with AWS X-Ray SDK, providing deep visibility into your application‚Äôs performance and service interactions.\nKey benefits you\u0026rsquo;ll gain from this workshop: Understand how AWS X-Ray traces requests across your backend APIs and database operations. Learn how to manage environment secrets securely using AWS Secrets Manager. Automate deployment using Elastic Beanstalk and monitor health metrics via CloudWatch. Visualize traces and debug issues quickly using AWS Application Signals. Replace traditional manual logging with structured, distributed tracing. Explore practical examples: product listing, uploading images, placing orders, and seeing their traces in real time. By the end of the workshop, you will have built and deployed a full-stack e-commerce app with tracing and monitoring best practices‚Äîready to scale and production-ready.\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/",
	"title": "Tracing and Debugging Node.js Applications with AWS X-Ray, CloudWatch, and MongoDB Atlas",
	"tags": [],
	"description": "",
	"content": "Tracing and Debugging Node.js Applications with AWS X-Ray, CloudWatch, and MongoDB Atlas Overall In this hands-on workshop, you will learn how to build, deploy, trace, and monitor a Node.js + React e-commerce web application using AWS services. We will walk through advanced tracing techniques using AWS X-Ray and CloudWatch, securely manage credentials with Secrets Manager, and store data on MongoDB Atlas. You\u0026rsquo;ll also integrate image uploads via Amazon S3 and deploy the entire stack using Elastic Beanstalk.\nContent Introduction and Architecture Overview Preparation Instrument Node.js Backend with AWS X-Ray SDK Deployment: Backend \u0026amp; Frontend Enable S3 Upload and Image Hosting Trace Requests from Frontend to Database Workshop Review and Common Issues Clean Up AWS Resources "
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/2-preparation/2.2-iam-and-secrets/2.2.2-create-iam-role/",
	"title": "Create IAM Role for Beanstalk",
	"tags": [],
	"description": "",
	"content": "Create an IAM role to be attached to Elastic Beanstalk EC2 instances. This allows the instances to interact with AWS X-Ray, S3, and Secrets Manager.\nRequired policies:\nAWSXRayFullAccess AmazonS3FullAccess SecretsManagerReadWrite AWSElasticBeanstalkWebTier Go to the IAM Roles Console to view or create roles for your environment.\nClick Create role at the top of the page. Create a new IAM Role Under Trusted entity type, select AWS service EC2\nCreate a new IAM Role Click Next to move to permissions.\nüìå Attach Policies In the Permissions step, search for and select the following policies: AWSElasticBeanstalkMulticontainerDocker AWSElasticBeanstalkWebTier AWSElasticBeanstalkWorkerTier AWSElasticBeanstalkEnhancedHealth AWSElasticBeanstalkManagedUpdatesCustomerRolePolicy SecretsManagerReadWrite AWSXRayDaemonWriteAccess Create a new IAM Role Click Next. üìù Name and Create the Role Enter a name for the role, for example:aws-elasticbeanstalk-ec2-role (Optional) Add a description such as:\nIAM role for Elastic Beanstalk EC2 instances with access to X-Ray, Secrets Manager, and Beanstalk features. Create a new IAM Role Click Create Role After creating the role, return to the IAM Roles Console and search for the role name you just created\n(e.g., EcommerceAppInstanceRole) to verify that it appears in the list. Create a new IAM Role 10. Attach Secrets Manager Policy to IAM Role\nTo allow your Elastic Beanstalk EC2 instances to securely retrieve MongoDB credentials from AWS Secrets Manager, you need to attach a custom policy to your IAM role (e.g., aws-elasticbeanstalk-ec2-role).\nSteps:\nGo to the IAM Roles Console. Click your role name (e.g., aws-elasticbeanstalk-ec2-role). Under the Permissions tab, click Add permissions ‚Üí Create inline policy. Choose the JSON tab, and paste the following: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:secretsmanager:ap-southeast-1:\u0026lt;your-account-id\u0026gt;:secret:mongodb/connection-*\u0026#34; } ] } üîÅ Replace \u0026lt;your-account-id\u0026gt; with your actual AWS account ID.\nClick Next ‚Üí Name the policy (e.g., SecretsManagerAccessPolicy). Click Create policy. üîç What This Policy Does Allows: secretsmanager:GetSecretValue Resource: Only for secrets named mongodb/connection-* in the ap-southeast-1 region Purpose: Lets your Node.js app (on Beanstalk) fetch MongoDB connection strings securely at runtime using the AWS SDK. Security: Access is scoped to only the required secret, avoiding unnecessary exposure. ‚úÖ Once attached, your Beanstalk instance can securely access secrets ‚Äî no need to hardcode credentials in .env files or deploy sensitive data.\n‚úÖ Make sure the attached policies look correct.\nYou can click the role name to review permissions and trust relationships.\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/4-deployment/4.2-deploy-frontend/",
	"title": "Deploy React Frontend to AWS Elastic Beanstalk",
	"tags": [],
	"description": "",
	"content": "In this section, you will deploy the React frontend of your e-commerce application by combining it into the same deployment as your Node.js backend using Elastic Beanstalk.\nUnlike S3/CloudFront hosting, this approach uses the Express backend to serve your frontend static files (dist/)‚Äîallowing seamless routing, cookies, and CORS under the same domain.\nüì¶ Download Frontend Source Code ‚¨áÔ∏è Download Frontend Source (frontend.zip)\nAfter downloading:\nExtract the archive Inside the extracted folder (frontend/), navigate to src/ Create a file named .env.production with the following content: VITE_API_URL=https://your-backend-env.ap-southeast-1.elasticbeanstalk.com/api Replace the URL with your actual backend Beanstalk environment.\n‚öôÔ∏è Build the Frontend Open a terminal in the frontend/ folder\nRun the following commands:\nnpm install npm run build This will generate a dist folder containing production-ready static assets.\nüöÄ Move dist/ to Backend and Deploy Copy the newly generated dist/ folder\nPaste it into your backend/ directory (next to server.js)\nYour backend structure should now look like:\nbackend/ ‚îú‚îÄ‚îÄ server.js ‚îú‚îÄ‚îÄ dist/ ‚îÇ ‚îú‚îÄ‚îÄ index.html ‚îÇ ‚îî‚îÄ‚îÄ assets/ ‚îú‚îÄ‚îÄ routes/ ‚îú‚îÄ‚îÄ .ebextensions/ ‚îî‚îÄ‚îÄ ... Re-zip the backend folder:\ncd backend zip -r ../ecommerce-backend-with-frontend.zip . Go to the Elastic Beanstalk Console\nSelect your existing ecommerce-app environment Elastic Beanstalk: Upload deployment package Click Upload and deploy Elastic Beanstalk: Select and deploy new version Choose the new zip file: ecommerce-backend-with-frontend.zip and label version-2 Elastic Beanstalk: Version label and deploy Click Deploy üåê Access the Application Visit your Beanstalk environment URL:\nhttp://ecommerce-env.eba-xxxx.ap-southeast-1.elasticbeanstalk.com You should see your React frontend being served ‚Äî fully integrated with your backend.\nFrontend deployed and accessible via Beanstalk URL The following code in server.js ensures static frontend routing works\napp.use(express.static(path.join(__dirname, \u0026#39;dist\u0026#39;))); app.get(\u0026#39;*\u0026#39;, (req, res) =\u0026gt; { res.sendFile(path.join(__dirname, \u0026#39;dist\u0026#39;, \u0026#39;index.html\u0026#39;)); }); üéâ Your full-stack e-commerce app is now deployed to AWS Elastic Beanstalk ‚Äî complete with frontend, backend, API, and X-Ray observability.\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/2-preparation/",
	"title": "Preparation",
	"tags": [],
	"description": "",
	"content": "In this section, you will complete all the essential preparation steps before deploying and tracing your application on AWS. These labs will help you:\nAWS Identity and Access Management (IAM) Set up your AWS account and enable X-Ray Create IAM users and roles with proper permissions Securely manage credentials using AWS Secrets Manager Integrate MongoDB Atlas with your backend using Mongoose Each lab is a critical foundation for a secure, observable, and production-ready deployment.\nLabs included:\n2.1 Create MongoDB Atlas Database 2.2 IAM and Secrets Management 2.3 Create Elastic Beanstalk Environment 2.4 MongoDB Integration 2.5 S3 Setup Complete these steps before moving on to backend instrumentation and deployment.\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/2-preparation/2.2-iam-and-secrets/",
	"title": "Preparing IAM and Secrets",
	"tags": [],
	"description": "",
	"content": "In this step, we will prepare the foundational AWS resources required to securely deploy and monitor our application using Elastic Beanstalk, AWS X-Ray, and MongoDB Atlas.\nContent Create IAM User for Development Create IAM Role for Beanstalk Create Secret in AWS Secrets Manager "
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/2-preparation/2.5-s3-setup/2.5.2-test-upload/",
	"title": "Test Image Upload to S3",
	"tags": [],
	"description": "",
	"content": "After creating your S3 bucket and configuring CORS, it\u0026rsquo;s time to test image uploads through the admin interface of your deployed application.\nYour backend is pre-configured to accept image files and store them in the correct bucket path using the uploadProductImage route.\n‚úÖ What you will verify Frontend can upload image files using the admin panel Image URLs are stored in S3 under products/ prefix URLs are publicly accessible (based on bucket policy) üß™ Step-by-step: Test Upload Go to your admin dashboard URL: http://your-backend-env.elasticbeanstalk.com Navigate to the Product Management or Add Product section Fill out required fields like: Product Name Price Category Brand SKU Click Upload Image button Select an image file (e.g., .jpg, .png) Wait for the upload to complete (you should see a preview or file name) Click Save or Create Product üîç Expected Result After a successful upload:\n‚úÖ The image is uploaded to your S3 bucket (e.g., ecommerce-products-2025) ‚úÖ The product entry will store the image URL like: https://ecommerce-products-2025.s3.ap-southeast-1.amazonaws.com/products/1699355589999-laptop.jpg ‚úÖ You can copy and paste the URL into a browser and see the image\n‚úÖ No CORS error in browser console\nüß∞ Behind the scenes Your image upload hits this backend endpoint:\nPOST /api/products/upload Content-Type: multipart/form-data Authorization: Bearer \u0026lt;admin-token\u0026gt; This is handled by:\nroutes/products.js\ncontrollers/productController.js ‚Üí uploadProductImage()\nIt uses AWS SDK v3 and X-Ray tracing to log detailed upload behavior.\nüß© Troubleshooting:\nProblem Solution ‚ùå Image not visible Ensure correct bucket name \u0026amp; region in code ‚ùå Access Denied Confirm IAM Role has AmazonS3FullAccess ‚ùå Image URL 403 Forbidden Make sure bucket policy allows s3:GetObject for the correct path üéâ Congratulations! You‚Äôve successfully completed S3 image upload integration and confirmed that your frontend + backend + bucket configuration works end-to-end.\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/2-preparation/2.3-create-beanstalk/2.3.2-configure-eb-env/",
	"title": "Update Elastic Beanstalk Environment Configuration",
	"tags": [],
	"description": "",
	"content": "In this step, you will review and update configuration settings for the Elastic Beanstalk environment you created earlier.\nThis includes:\nSetting up environment variables Ensuring IAM role is attached Enabling the AWS X-Ray daemon Verifying security group access and instance health üîß Step 1: Open Environment Settings\nGo to Elastic Beanstalk Console Select your environment (e.g. ecommerce-env) Click Configuration üß™ Step 2: Edit Software Settings\nClick Edit in the Software section:\nAdd or update these environment variables:\nKey Value PORT 8080 NODE_ENV production AWS_XRAY_DAEMON_ADDRESS 127.0.0.1:2000 JWT_SECRET (your custom JWT secret) REFRESH_TOKEN_SECRET (your refresh token secret) ALLOWED_ORIGINS http://localhost:5173,https://your-frontend.com ‚úÖ Ensure PORT matches what your Node.js server listens on (default is 8080).\nüîê Step 3: Attach IAM Instance Profile\nClick Edit in the Security section:\nSet EC2 instance profile to:\nEcommerceAppInstanceRole\n(Created earlier with X-Ray and Secrets Manager permissions) This ensures your app can:\nRead secrets from AWS Secrets Manager Send trace data to AWS X-Ray Access S3 if needed ‚öôÔ∏è Step 4: Ensure X-Ray Daemon Is Running\nEnsure your ecommerce-backend.zip contains:\nxray.config file\nThis file configures the EC2 instance to install and start the AWS X-Ray daemon on port 2000.\nSample .ebextensions/xray.config:\nfiles: \u0026#34;/etc/xray-daemon.cfg\u0026#34;: mode: \u0026#34;000644\u0026#34; owner: root group: root content: | { \u0026#34;Daemon\u0026#34;: { \u0026#34;BindAddress\u0026#34;: \u0026#34;127.0.0.1:2000\u0026#34;, \u0026#34;Region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34; } } services: sysvinit: xray: enabled: true ensureRunning: true files: - /etc/xray-daemon.cfg ‚úÖ Step 5: Redeploy (if needed) If you\u0026rsquo;ve made changes to your environment settings or zip package:\nGo to Elastic Beanstalk \u0026gt; Application versions Upload and deploy the updated .zip Wait for green health status üîç Confirm everything is working:\nVisit /health endpoint ‚Üí should show xray: enabled Go to AWS X-Ray Console \u0026gt; Service Map ‚Üí should show your backend service Check Logs \u0026gt; Request logs in Beanstalk if issues arise "
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/2-preparation/2.2-iam-and-secrets/2.2.3-create-secret/",
	"title": "Create and Use Secret in AWS Secrets Manager",
	"tags": [],
	"description": "",
	"content": "In this section, you will learn how to securely store and retrieve sensitive credentials using AWS Secrets Manager.\nInstead of hardcoding MongoDB connection strings or AWS keys in .env files or source code, you\u0026rsquo;ll use AWS Secrets Manager to store secrets and access them securely from your backend application.\nüîê Step-by-step: Create a secret in Secrets Manager Go to the Secrets Manager Console\nClick Store a new secret\nStore a new secret in AWS Secrets Manager Choose Other type of secrets\nThis allows you to define custom key-value pairs manually. In the Plaintext section, enter the following (or modify as needed): { \u0026#34;MONGODB_URI\u0026#34;: \u0026#34;mongodb+srv://\u0026lt;user\u0026gt;:\u0026lt;pass\u0026gt;@cluster.mongodb.net/ecommerce\u0026#34;, \u0026#34;AWS_ACCESS_KEY\u0026#34;: \u0026#34;\u0026lt;your-access-key\u0026gt;\u0026#34;, \u0026#34;AWS_SECRET_KEY\u0026#34;: \u0026#34;\u0026lt;your-secret-key\u0026gt;\u0026#34; } Store a new secret in AWS Secrets Manager Replace \u0026lt;user\u0026gt;, \u0026lt;password\u0026gt;, \u0026lt;your-access-key\u0026gt;, \u0026lt;your-secret-key\u0026gt; and actual credentials with your own.\nClick Next\nEnter a name for the secret\nExample: mongodb/connection\n‚úÖ This name will be used in your application to retrieve the secret.\nYou can optionally add a description and tags.\nLeave automatic rotation disabled (for now), then click Next\nOn the Review page, double-check your inputs\nThen click Store to create the secret.\nYou should see a confirmation message and the new secret listed in the Secrets Manager dashboard.\nüß™ Confirm the Secret Click on the secret name (mongodb/connection) to open it.\nVerify that the key-value pairs were saved correctly.\nView saved secret in Secrets Manager üßë‚Äçüíª How to use the secret in Node.js (runtime access) To fetch the secret from your backend app:\nInstall AWS SDK v3 if you haven\u0026rsquo;t: npm install @aws-sdk/client-secrets-manager Use the following code in your backend (e.g. server.js or a config module): const { SecretsManagerClient, GetSecretValueCommand } = require(\u0026#39;@aws-sdk/client-secrets-manager\u0026#39;); const client = new SecretsManagerClient({ region: \u0026#39;ap-southeast-1\u0026#39; }); async function getMongoURI() { const command = new GetSecretValueCommand({ SecretId: \u0026#39;mongodb/connection\u0026#39; }); const data = await client.send(command); const secret = JSON.parse(data.SecretString); return secret.MONGODB_URI; } "
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/2-preparation/2.3-create-beanstalk/",
	"title": "Create Elastic Beanstalk Environment",
	"tags": [],
	"description": "",
	"content": "üöÄ What is AWS Elastic Beanstalk? ElasticBeanstalk Elastic Beanstalk is a Platform-as-a-Service (PaaS) offering from AWS that makes it easy to deploy, manage, and scale applications. It supports several languages and platforms including Node.js, Java, Python, and .NET.\nWith Elastic Beanstalk, you focus on your code, and AWS handles the infrastructure‚Äîlike provisioning EC2 instances, load balancers, auto scaling, monitoring, and deployments.\n‚úÖ Key Benefits Zero infrastructure management ‚Äî no need to manually provision EC2, security groups, or scaling groups Built-in monitoring via CloudWatch and health dashboards Easy deployments via zip file or Git Integrated with IAM, X-Ray, S3, and other AWS services Support for environment variables and secret injection üéØ In this step, you will: Upload your Node.js backend as a zipped archive Create an Elastic Beanstalk environment Attach an IAM role to allow access to: AWS X-Ray Secrets Manager S3 Buckets Enable the X-Ray daemon using .ebextensions Set up environment variables like JWT_SECRET, ALLOWED_ORIGINS, and PORT Once completed, your backend application will be fully deployed in a production-grade, autoscaled, and observable AWS environment.\n‚û°Ô∏è Continue to 2.3.1 ‚Äì Deploy Backend Application to begin setup.\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/3-xray-sdk/",
	"title": "Instrument Node.js Backend with AWS X-Ray SDK",
	"tags": [],
	"description": "",
	"content": "In this section, you will explore how AWS X-Ray SDK is fully integrated into the Node.js backend to provide tracing for:\nIncoming HTTP requests MongoDB queries Internal business logic Errors and health diagnostics All necessary code is already implemented in server.js. This step is about understanding, verifying, and testing the tracing setup.\nüìÇ Source location File: backend/server.js Module: aws-xray-sdk üß† Key Features of the Integration ‚úÖ 1. Auto-tracing of HTTP requests const AWSXRay = require(\u0026#39;aws-xray-sdk\u0026#39;); AWSXRay.captureHTTPsGlobal(require(\u0026#39;http\u0026#39;), true); AWSXRay.setDaemonAddress(\u0026#39;127.0.0.1:2000\u0026#39;); app.use(AWSXRay.express.openSegment(\u0026#39;EcommerceApp\u0026#39;)); Automatically traces all incoming Express routes. Captures upstream headers (from frontend or ALB). Sends segments to the local X-Ray daemon at 127.0.0.1:2000 if run local.\n‚úÖ 2. MongoDB Tracing via Custom Subsegments const segment = AWSXRay.getSegment(); const subsegment = segment.addNewSubsegment(\u0026#39;MongoDB - Connect\u0026#39;); // ... await mongoose.connect(uri, options); subsegment.close(); This pattern allows you to trace database-specific logic. It\u0026rsquo;s used in the connectMongoDB() function.\n‚úÖ 3. CORS Headers \u0026amp; Trace Propagation allowedHeaders: [\u0026#39;Content-Type\u0026#39;, \u0026#39;Authorization\u0026#39;, \u0026#39;X-Amzn-Trace-Id\u0026#39;, \u0026#39;x-amz-security-token\u0026#39;], exposedHeaders: [\u0026#39;Set-Cookie\u0026#39;, \u0026#39;X-Amzn-Trace-Id\u0026#39;] This setup ensures full trace propagation across frontend ‚Üí backend ‚Üí AWS services.\n‚úÖ 4. Structured Logging with Trace ID const traceId = req.headers[\u0026#39;x-amzn-trace-id\u0026#39;] || \u0026#39;local\u0026#39;; console.log(`[${traceId}] ${req.method} ${req.originalUrl}`, { headers, body }); Allows correlating logs with traces in the X-Ray console.\n‚úÖ 5. X-Ray Segment Closure app.use(AWSXRay.express.closeSegment()); This is necessary to finalize each trace, and should be used after all routes are registered.\nü©∫ Health Check + X-Ray Visibility The /health endpoint also checks for:\nMongoDB connectivity via ping() X-Ray daemon address availability Sample output:\n{ \u0026#34;status\u0026#34;: \u0026#34;healthy\u0026#34;, \u0026#34;services\u0026#34;: { \u0026#34;database\u0026#34;: \u0026#34;connected\u0026#34;, \u0026#34;xray\u0026#34;: \u0026#34;enabled\u0026#34; } // ... } üß™ Verify in AWS Console Open X-Ray Console ‚Üí Service Map\nFind EcommerceApp\nInspect traces for:\nLatency MongoDB errors End-to-end flows from frontend ‚úÖ Summary Your backend is instrumented with X-Ray. Traces capture detailed API + DB behavior. Logs are correlated with trace IDs. Secure and production-ready. üéØ Tracing Details with Annotation and Metadata In this backend project, each major API operation is wrapped using a helper function that adds X-Ray subsegments, with detailed annotations and metadata to enhance observability.\nüìç Location in Source Code File: controllers/productController.js Wrapper Function: withXRay(segmentName, fn) üß© What Are Annotations and Metadata? Annotations are indexed key‚Äìvalue pairs ‚Äî used for filtering in the X-Ray console. Metadata are key‚Äìvalue data (any JSON type) ‚Äî used for detailed trace context. ‚úÖ Examples in Code getProducts API When users view the product list, the system captures:\nsegment.addAnnotation(\u0026#39;category\u0026#39;, category || \u0026#39;all\u0026#39;); segment.addAnnotation(\u0026#39;page\u0026#39;, parseInt(page)); segment.addMetadata(\u0026#39;query_params\u0026#39;, { category, brand, sort, page, limit }); segment.addMetadata(\u0026#39;category_counts\u0026#39;, categoryCounts); ‚Üí This helps you trace:\nWhat filters were used How many products were found Which categories were present uploadProductImage API When admins upload a product image to S3:\ns3Segment.addAnnotation(\u0026#39;upload_success\u0026#39;, true); s3Segment.addAnnotation(\u0026#39;image_url\u0026#39;, imageUrl); s3Segment.addMetadata(\u0026#39;upload_result\u0026#39;, { imageUrl, key: params.Key, bucket: params.Bucket }); ‚Üí You can inspect uploaded image details or trace failures (e.g., S3 permission issues).\ncreateProduct API During new product creation:\ndbSegment.addAnnotation(\u0026#39;product_created\u0026#39;, true); dbSegment.addMetadata(\u0026#39;product_info\u0026#39;, { id: product._id, name, sku, image, price, category }); ‚Üí Lets you trace what product was added and whether the creation succeeded or failed.\n‚ö†Ô∏è Error Tracing In case of failure, the following are added:\nsegment.addAnnotation(\u0026#39;status\u0026#39;, \u0026#39;error\u0026#39;); segment.addAnnotation(\u0026#39;error_type\u0026#39;, err.name); segment.addMetadata(\u0026#39;error_stack\u0026#39;, err.stack); segment.addMetadata(\u0026#39;error_context\u0026#39;, { operation: segmentName, timestamp: new Date().toISOString(), args_count: args.length }); ‚Üí This allows filtering for failed requests and viewing complete error context in AWS X-Ray \u0026gt; Trace Details.\nüîç How to View These in X-Ray Console Go to CloudWatch Home ‚Üí Application Signals (APM) ‚ÜíTraces CloudWatch Traces Filter traces using annotations, e.g.:\nannotation.status = \u0026#34;success\u0026#34; Filter traces by annotation in CloudWatch Trace details in CloudWatch Click into a trace ‚Üí View subsegments ‚Üí Check Metadata or Annotations tab Annotations and Metadata in CloudWatch Trace üí° Note: This structured tracing makes debugging, auditing, and performance monitoring significantly easier in production environments.\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/4-deployment/",
	"title": "Deployment Backend and Frontend",
	"tags": [],
	"description": "",
	"content": "In this chapter, you will deploy both the backend (Node.js + MongoDB + AWS X-Ray) and the frontend (React + Vite) of the e-commerce application to AWS infrastructure.\nWe will cover:\nüìå 4.1 Deploy Backend to Elastic Beanstalk Deploy your Node.js backend to AWS Elastic Beanstalk Use pre-configured code with: AWS X-Ray tracing MongoDB Atlas integration Secrets Manager Auto health checks and logging Verify your deployment with /health and /api/status Ensure traces are visible in the AWS X-Ray Console üëâ See: 4.1 Deploy Backend to AWS Elastic Beanstalk\nüìå 4.2 Deploy React Frontend to AWS Build your React Vite frontend Deploy using: Option A: Amazon S3 + CloudFront (static hosting) Option B: Second Elastic Beanstalk environment (optional) Configure the frontend to talk to your backend securely Trigger end-to-end traces from frontend ‚Üí backend ‚Üí database üëâ See: 7.2 Deploy React Frontend to AWS (S3/CloudFront or Beanstalk)\nOnce this chapter is completed, you will have your entire MERN stack application fully deployed on AWS with production-grade observability using X-Ray, CloudWatch, and Secrets Manager.\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/2-preparation/2.4-mongodb-integration/",
	"title": "Integrate MongoDB Atlas and Mongoose",
	"tags": [],
	"description": "",
	"content": "In this section, you will verify how the backend application securely connects to MongoDB Atlas using Mongoose and AWS Secrets Manager.\nYou don\u0026rsquo;t need to write the logic from scratch. The complete integration has already been implemented in the server.js file included in the workshop source code.\nüì¶ Download Source Code üëâ Download Workshop Code (.zip)\nExtract and open the backend/ folder. All database connection logic is located in server.js.\nüß† How It Works AWS Secrets Manager stores the MongoDB connection string under the key mongodb/connection At runtime, the app retrieves that value using the AWS SDK: const client = new SecretsManagerClient({ region: \u0026#39;ap-southeast-1\u0026#39; }); const command = new GetSecretValueCommand({ SecretId: \u0026#39;mongodb/connection\u0026#39; }); const data = await client.send(command); const uri = JSON.parse(data.SecretString).MONGODB_URI; Then it connects to MongoDB using:\nawait mongoose.connect(uri, { ...connectionOptions }); üîç What to Look For Open this function in server.js:\nconst connectMongoDB = async (maxRetries = 5, retryDelay = 3000) =\u0026gt; { ... } This includes:\nAuto-retry connection logic Timeout settings Pool sizing Graceful error handling üß™ Verify the Connection Once you deploy the backend:\nGo to /health endpoint You should see: \u0026#34;services\u0026#34;: { \u0026#34;database\u0026#34;: \u0026#34;connected\u0026#34;, \u0026#34;xray\u0026#34;: \u0026#34;enabled\u0026#34; } If MongoDB is disconnected or credentials are wrong, the status will show \u0026quot;database\u0026quot;: \u0026quot;disconnected\u0026quot;.\nüõ°Ô∏è Security Reminder MongoDB credentials are not hardcoded Secrets are stored in AWS Secrets Manager Only the Beanstalk EC2 role can access them ‚úÖ With this setup, your backend is securely and reliably connected to MongoDB Atlas in production-ready fashion.\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/5-s3-upload/",
	"title": "Enable S3 Upload and Image Hosting",
	"tags": [],
	"description": "",
	"content": "In this section, you\u0026rsquo;ll verify and test image uploading using Amazon S3, integrated directly into your backend API.\nYour backend has been pre-configured with:\nAWS SDK v3 (@aws-sdk/client-s3) Multer for processing form-data uploads X-Ray tracing for upload activity Logic to generate and return public URLs from your S3 bucket ‚úÖ What You\u0026rsquo;ll Do Confirm your S3 bucket (e.g., ecommerce-products-2025) was created correctly Upload product images from the admin dashboard Verify image URLs are accessible from Amazon S3 Confirm tracing appears in AWS X-Ray üîç How the Upload Works The backend route responsible for file uploads is:\nPOST /api/products/upload It uses the uploadProductImage controller in controllers/productController.js.\nThis function does the following:\nParses the file using multer:\nconst upload = multer(); Accepts multipart file as image field\nSends it as a buffer to S3\nInitializes the S3 client in your AWS region, using environment variables:\nconst s3Client = new S3Client({ region: process.env.AWS_REGION || \u0026#39;ap-southeast-1\u0026#39;, credentials: { accessKeyId: process.env.AWS_ACCESS_KEY, secretAccessKey: process.env.AWS_SECRET_KEY } }); Builds a file path and uploads the file:\nconst params = { Bucket: \u0026#39;ecommerce-products-2025\u0026#39;, // Make sure this matches your bucket name! Key: `products/${Date.now()}-${req.file.originalname}`, Body: req.file.buffer, ContentType: req.file.mimetype }; await s3Client.send(new PutObjectCommand(params)); Returns the S3 URL like:\nhttps://ecommerce-products-2025.s3.ap-southeast-1.amazonaws.com/products/your-image.jpg üß™ Testing the Upload Log in to your app as Admin Go to Admin Dashboard ‚Üí Add Product Select an image and click Upload Submit the form After saving, you should see the uploaded image appear next to the product. The image URL should start with:\nhttps://ecommerce-products-2025.s3.ap-southeast-1.amazonaws.com/... ‚úÖ You can click this link and view it publicly.\n‚öôÔ∏è What Needs to Be Correct ‚úÖ Bucket Name in productController.js: Make sure this line:\nBucket: \u0026#39;ecommerce-products-2025\u0026#39; matches your actual S3 bucket name (the one you created manually or in lab step 2.5.1 - Create S3 Bucket).\n‚úÖ IAM Role used by Beanstalk must have this policy:\nAmazonS3FullAccess Or a custom policy allowing s3:PutObject, s3:GetObject for your bucket\n‚úÖ CORS Settings in the S3 bucket: Make sure you‚Äôve configured the following:\n\u0026lt;CORSRule\u0026gt; \u0026lt;AllowedOrigin\u0026gt;*\u0026lt;/AllowedOrigin\u0026gt; \u0026lt;AllowedMethod\u0026gt;GET\u0026lt;/AllowedMethod\u0026gt; \u0026lt;AllowedMethod\u0026gt;POST\u0026lt;/AllowedMethod\u0026gt; \u0026lt;AllowedMethod\u0026gt;PUT\u0026lt;/AllowedMethod\u0026gt; \u0026lt;AllowedHeader\u0026gt;*\u0026lt;/AllowedHeader\u0026gt; \u0026lt;/CORSRule\u0026gt; üì¶ Sample Environment Variables These environment variables must be present in your Elastic Beanstalk config or .env:\nAWS_REGION=ap-southeast-1 AWS_ACCESS_KEY=your-access-key AWS_SECRET_KEY=your-secret-key Without these, S3Client will not authenticate correctly and uploads will fail.\nüîé X-Ray Tracing Every file upload is traced via AWS X-Ray:\nFileValidation segment logs:\nfile size mimetype X-Ray: File validation segment logs S3Upload segment logs: image_url key upload result or error X-Ray: S3 upload segment logs Go to X-Ray Console and navigate to the Service Map to confirm upload activity. üéâ Once verified, you now have a complete S3 image hosting integration with traceable uploads, public file access, and admin-managed product creation.\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/2-preparation/2.5-s3-setup/",
	"title": "Setup Amazon S3 for Image Upload",
	"tags": [],
	"description": "",
	"content": "‚òÅÔ∏è Amazon S3 Overview Amazon Simple Storage Service (Amazon S3) Amazon S3 (Simple Storage Service) is a scalable, durable, and highly available object storage service provided by AWS. It allows developers to store and retrieve any amount of data at any time, from anywhere on the web.\nüí° Common Use Cases Hosting static files like HTML, CSS, JS Storing user-uploaded images, videos, or documents Serving downloadable content Acting as backup or archive storage Supporting data lakes and machine learning workflows üõçÔ∏è What S3 Does in This Workshop In this e-commerce workshop, Amazon S3 is used to:\nStore uploaded product images Serve images via public URLs Integrate securely with your backend using IAM and AWS SDK Log and trace upload activity using AWS X-Ray Your backend is preconfigured to upload product images to a specified S3 bucket (e.g., ecommerce-products-2025) and return accessible URLs for display in the UI.\n‚úÖ What You\u0026rsquo;ll Do in This Section Create a new S3 bucket Set up permissions and public access Configure CORS policy to allow uploads from your frontend Upload an image from the admin dashboard Verify that the image is accessible online Confirm that upload activity is traceable in AWS X-Ray üìÅ Related Source Code This functionality is handled in the backend by:\nüì¶ backend/ ‚îî‚îÄ‚îÄ controllers/productController.js ‚îî‚îÄ‚îÄ uploadProductImage() // S3 + X-Ray integration You can test it via:\nPOST /api/products/upload üëâ Continue to the next step: Create S3 Bucket for Product Images\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/6-end-to-end-tracing/",
	"title": "Trace Requests from Frontend to Database",
	"tags": [],
	"description": "",
	"content": "In this section, you will perform end-to-end tracing of user actions from the React frontend, through the backend, down to MongoDB, all visible in AWS X-Ray.\nüß™ Try This Open your frontend (hosted on S3 or Beanstalk)\nRegister a new account\nRegister a new user account Log in using your newly created credentials\nLogin to your account Browse to a product\nView product details Click \u0026ldquo;Add to cart\u0026rdquo;, then proceed to checkout\nAdd product to cart and proceed to checkout Place an order\nPlace the order üîç Now check AWS X-Ray: Go to CloudWatch Console ‚Üí Trace Map You should see: Frontend traced request ‚Üí Backend service (EcommerceApp) X-Ray trace: frontend to backend X-Ray trace: backend to MongoDB Backend ‚Üí MongoDB operation X-Ray trace: segment details Click any trace to see Segment details. ‚úÖ This proves: Frontend sends trace headers (X-Amzn-Trace-Id) Backend captures and logs segments Database activity is also recorded "
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/7-review/",
	"title": "Workshop Review and Common Issues, Future Enhancements",
	"tags": [],
	"description": "",
	"content": "‚úÖ What You\u0026rsquo;ve Accomplished By completing this workshop, you have successfully:\nüöÄ Deployed a full-stack Node.js + React application to AWS üì¶ Used Elastic Beanstalk for deployment and management üß© Integrated AWS X-Ray for end-to-end distributed tracing üîê Secured credentials using AWS Secrets Manager ‚òÅÔ∏è Connected to MongoDB Atlas as a managed NoSQL database üìä Used CloudWatch for basic monitoring and health checks üñºÔ∏è Enabled image uploads to Amazon S3 ‚ö†Ô∏è Common Issues and Troubleshooting ‚ùå Traces not showing in X-Ray?\nEnsure .ebextensions/xray.config is deployed Check IAM Role has AWSXRayFullAccess Verify AWS_XRAY_DAEMON_ADDRESS is set to 127.0.0.1:2000 ‚ùå MongoDB connection failing?\nEnsure the secret name exists in Secrets Manager Make sure the current IP or EC2 security group is whitelisted in MongoDB Atlas ‚ùå CORS or cookies not working?\nDouble-check the ALLOWED_ORIGINS environment variable Ensure frontend and backend are served from the correct domains ‚ùå S3 upload issues?\nConfirm correct CORS settings and IAM permissions for the S3 bucket Check if your uploaded files are publicly accessible (via S3 Bucket Policy) üöß Future Enhancements Although this version of the workshop provides a complete deployment pipeline, here are some planned features to enhance it further:\nüìú Enable AWS CloudTrail\nCapture API activity logs for auditing and visibility across services.\nüìà Integrate Auto Scaling Groups\nAutomatically scale EC2 instances based on traffic or CPU usage using Elastic Beanstalk\u0026rsquo;s scaling options.\nüîí Advanced secrets rotation\nEnable automatic rotation of secrets for MongoDB or AWS credentials.\nüìâ Use Amazon CloudWatch Alarms\nAlert on high memory, CPU, or errors per minute in real time.\nüß™ Integrate CI/CD with CodePipeline + CodeBuild\nAutomate your build and deployment pipeline for every code push to GitHub.\nüõ∞Ô∏è Enable VPC private subnets\nImprove security by running databases and internal services in private subnets.\nüåê Use Route 53 with HTTPS + Custom Domain\nMap your Beanstalk environments or CloudFront distributions to your own domain with SSL certificates.\nüéâ Congratulations!\nYou\u0026rsquo;ve deployed a production-ready full-stack app with AWS observability, secret management, and database connectivity.\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/8-cleanup/",
	"title": "Clean Up AWS Resources",
	"tags": [],
	"description": "",
	"content": "To avoid ongoing AWS charges, it‚Äôs important to delete the resources you created during the workshop. This step is especially crucial if you are using the AWS Free Tier, as some services (like MongoDB Atlas, EC2, or CloudWatch Logs) may incur charges over time.\nüßπ Resources to Delete Here‚Äôs how to clean up each service:\n1Ô∏è‚É£ Elastic Beanstalk Go to the Elastic Beanstalk Console\nSelect your environment (e.g. ecommerce-app)\nClick Actions ‚Üí Terminate environment\n‚ö†Ô∏è This will terminate EC2, Load Balancer, Auto Scaling, and S3 resources created by Beanstalk. Terminate Elastic Beanstalk environment Confirm deletion\nConfirm environment termination 2Ô∏è‚É£ Amazon S3 Buckets Go to the S3 Console Select your bucket (e.g. ecommerce-products-2025) Select S3 bucket to delete Empty the bucket contents first: Click Empty Empty S3 bucket before deletion Confirm deletion Then click Delete bucket Delete S3 bucket Confirm S3 bucket deletion ‚ö†Ô∏è Buckets must be emptied before deletion.\n3Ô∏è‚É£ MongoDB Atlas Cluster If you created a MongoDB Atlas cluster, deleting it will stop billing from MongoDB (not AWS).\nGo to MongoDB Atlas Navigate to your project 3.leave project\nLeave MongoDB Atlas project Confirm leaving MongoDB Atlas project Click Cluster ‚Üí Terminate Terminate MongoDB Atlas cluster Confirm cluster termination Delete the project if not used again Delete MongoDB Atlas project 4Ô∏è‚É£ AWS Secrets Manager Go to Secrets Manager Select your secret (e.g. mongodb/connection, ecommerce-secrets) Click Actions ‚Üí Delete Confirm deletion Delete secret in AWS Secrets Manager Secrets are scheduled for deletion in 7 days (you can force immediate deletion via CLI).\n5Ô∏è‚É£ IAM Users and Roles Go to the IAM Console Delete: IAM user (e.g. ecommerce-user) IAM roles (e.g. EcommerceAppInstanceRole) IAM policies created for the workshop (if custom) ‚úÖ This ensures your workshop credentials are not exposed or reused accidentally.\n6Ô∏è‚É£ CloudWatch Logs (Optional) Go to CloudWatch Logs Navigate to Logs ‚Üí Log groups Select groups such as: /aws/elasticbeanstalk/... /aws/lambda/... (if used) Click Actions ‚Üí Delete log group ‚ö†Ô∏è CloudWatch logs may incur costs over time if retained.\n‚úÖ Final Tip Wait a few minutes after deleting everything. Go to the Billing Console to check for active resources or costs. If you see unexpected charges:\nUse AWS Cost Explorer Check Resource Groups or Trusted Advisor üéâ You‚Äôve Successfully Cleaned Up!\nThanks for completing the workshop. You‚Äôve built a full-stack AWS application and now closed all active resources to prevent charges.\n"
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://nguyenvantaiit.github.io/Workshop-AWS-deployment-With-NodeJS-ReactJS-MongoDBatlas/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]